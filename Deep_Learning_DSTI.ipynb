{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX2w0wctDDlX"
      },
      "source": [
        "The command installs Python packages for NLP and dataset management, evaluation tools, and 7z archive handling with the '-q' flag for quiet installation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "-DjYdXVIW8t_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9150d22e-d9e9-44af-c4b2-c549bd3fa0ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install transformers[sentencepiece] datasets sacrebleu rouge_score py7zr -q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTsyCxpFDMDP"
      },
      "source": [
        "The command \"!nvidia-smi\" is used to display information about NVIDIA GPU status and usage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Y6eitZRiL4g",
        "outputId": "01197f1d-734d-499d-efa7-7d8bfce543d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Nov 24 14:34:40 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqCuKYQwDUyD"
      },
      "source": [
        "The code imports various Python libraries, including the Hugging Face Transformers library, Matplotlib, datasets, NLTK for text processing, and sets up the environment for sequence-to-sequence language modeling."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio -y\n",
        "!pip install torch torchvision torchaudio -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9YNYNiuVwwfL",
        "outputId": "77472b35-e362-4075-eee5-e89804359180"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.1.1\n",
            "Uninstalling torch-2.1.1:\n",
            "  Successfully uninstalled torch-2.1.1\n",
            "Found existing installation: torchvision 0.16.0+cu118\n",
            "Uninstalling torchvision-0.16.0+cu118:\n",
            "  Successfully uninstalled torchvision-0.16.0+cu118\n",
            "Found existing installation: torchaudio 2.1.0+cu118\n",
            "Uninstalling torchaudio-2.1.0+cu118:\n",
            "  Successfully uninstalled torchaudio-2.1.0+cu118\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torch\n",
            "  Using cached torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.16.1-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
            "Collecting torchaudio\n",
            "  Using cached torchaudio-2.1.1-cp310-cp310-manylinux1_x86_64.whl (3.3 MB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: torch, torchvision, torchaudio\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-2.1.1 torchaudio-2.1.1 torchvision-0.16.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w7bzxR4Yo7X",
        "outputId": "d7bf1eec-a547-47a5-d46e-c9551f1870f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -orch (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, set_seed\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset\n",
        "import pandas as pd\n",
        "from datasets import load_dataset, load_metric\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "nltk.download(\"punkt\")\n",
        "!pip install transformers -U\n",
        "!pip install accelerate -U"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQxg5I2kDd2b"
      },
      "source": [
        "The code initializes a sequence-to-sequence model using the \"google/pegasus-cnn_dailymail\" checkpoint and sets the device to GPU if available, otherwise to CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Avn2t5WwYo4v",
        "outputId": "130d5f7b-cab3-4b0d-d0a3-252eab24a51d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model_pegasus = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUZ1hY5YDn4m"
      },
      "source": [
        "This function splits a list of elements into smaller batches for simultaneous processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "SBYkSKNXZjKQ"
      },
      "outputs": [],
      "source": [
        "def create_data_batches(list_of_elements, batch_size):\n",
        "    \"\"\"Split the dataset into smaller batches for simultaneous processing.\n",
        "    Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
        "    for i in range(0, len(list_of_elements), batch_size):\n",
        "        yield list_of_elements[i : i + batch_size]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRDvMb18D1RX"
      },
      "source": [
        "This function calculates ROUGE (Recall-Oriented Understudy for Gisting Evaluation) scores on a test dataset using a pre-trained language model for summarization and specified tokenizer. It processes the data in batches and returns the computed ROUGE scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xRzbACdqYo2R"
      },
      "outputs": [],
      "source": [
        "def evaluate_model_metric(test_data, evaluation_metric, text_model, text_tokenizer,\n",
        "                           batch_size=16, device=device,\n",
        "                           text_column=\"article\",\n",
        "                           summary_column=\"highlights\"):\n",
        "    text_batches = list(create_data_batches(test_data[text_column], batch_size))\n",
        "    target_batches = list(create_data_batches(test_data[summary_column], batch_size))\n",
        "\n",
        "    for text_batch, target_batch in tqdm(\n",
        "        zip(text_batches, target_batches), total=len(text_batches)):\n",
        "        inputs = text_tokenizer(text_batch, max_length=1024, truncation=True,\n",
        "                                padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "        summaries = text_model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
        "                                       attention_mask=inputs[\"attention_mask\"].to(device),\n",
        "                                       length_penalty=0.8, num_beams=8, max_length=128)\n",
        "\n",
        "        decoded_summaries = [text_tokenizer.decode(s, skip_special_tokens=True,\n",
        "                                                   clean_up_tokenization_spaces=True)\n",
        "                             for s in summaries]\n",
        "\n",
        "        decoded_summaries = [d.replace(\"\", \" \") for d in decoded_summaries]\n",
        "        evaluation_metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "\n",
        "    computed_score = evaluation_metric.compute()\n",
        "    return computed_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rd7_MtTaot4"
      },
      "source": [
        "### Load data\n",
        "\n",
        "Link: https://huggingface.co/datasets/samsum\n",
        "\n",
        "This code loads the \"samsum\" dataset, prints the lengths of dataset splits, displays the available features, and shows a dialogue and its corresponding summary from the test split."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BGBwbDdaBMn",
        "outputId": "476da82f-8a4f-4748-b365-a90dca1fa319"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Split lengths: [14732, 819, 818]\n",
            "Features: ['id', 'dialogue', 'summary']\n",
            "\n",
            "Dialogue:\n",
            "Eric: MACHINE!\r\n",
            "Rob: That's so gr8!\r\n",
            "Eric: I know! And shows how Americans see Russian ;)\r\n",
            "Rob: And it's really funny!\r\n",
            "Eric: I know! I especially like the train part!\r\n",
            "Rob: Hahaha! No one talks to the machine like that!\r\n",
            "Eric: Is this his only stand-up?\r\n",
            "Rob: Idk. I'll check.\r\n",
            "Eric: Sure.\r\n",
            "Rob: Turns out no! There are some of his stand-ups on youtube.\r\n",
            "Eric: Gr8! I'll watch them now!\r\n",
            "Rob: Me too!\r\n",
            "Eric: MACHINE!\r\n",
            "Rob: MACHINE!\r\n",
            "Eric: TTYL?\r\n",
            "Rob: Sure :)\n",
            "\n",
            "Summary:\n",
            "Eric and Rob are going to watch a stand-up on youtube.\n"
          ]
        }
      ],
      "source": [
        "dataset_samsum = load_dataset(\"samsum\")\n",
        "split_lengths = [len(dataset_samsum[split])for split in dataset_samsum]\n",
        "print(f\"Split lengths: {split_lengths}\")\n",
        "print(f\"Features: {dataset_samsum['train'].column_names}\")\n",
        "print(\"\\nDialogue:\")\n",
        "print(dataset_samsum[\"test\"][1][\"dialogue\"])\n",
        "print(\"\\nSummary:\")\n",
        "print(dataset_samsum[\"test\"][1][\"summary\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3VfNRNCbiiQ"
      },
      "source": [
        "# Evaluating PEGASUS on SAMSum\n",
        "\n",
        "\n",
        "This code accesses the dialogue from the \"samsum\" dataset's test split at index 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "KS10obRRbuoH",
        "outputId": "c6ef78b0-9424-4c67-da06-16265ba399aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Ollie: Hi , are you in Warsaw\\r\\nJane: yes, just back! Btw are you free for diner the 19th?\\r\\nOllie: nope!\\r\\nJane: and the  18th?\\r\\nOllie: nope, we have this party and you must be there, remember?\\r\\nJane: oh right! i lost my calendar..  thanks for reminding me\\r\\nOllie: we have lunch this week?\\r\\nJane: with pleasure!\\r\\nOllie: friday?\\r\\nJane: ok\\r\\nJane: what do you mean \" we don\\'t have any more whisky!\" lol..\\r\\nOllie: what!!!\\r\\nJane: you just call me and the all thing i heard was that sentence about whisky... what\\'s wrong with you?\\r\\nOllie: oh oh... very strange! i have to be carefull may be there is some spy in my mobile! lol\\r\\nJane: dont\\' worry, we\\'ll check on friday.\\r\\nOllie: don\\'t forget to bring some sun with you\\r\\nJane: I can\\'t wait to be in Morocco..\\r\\nOllie: enjoy and see you friday\\r\\nJane: sorry Ollie, i\\'m very busy, i won\\'t have time for lunch  tomorrow, but may be at 6pm after my courses?this trip to Morocco was so nice, but time consuming!\\r\\nOllie: ok for tea!\\r\\nJane: I\\'m on my way..\\r\\nOllie: tea is ready, did you bring the pastries?\\r\\nJane: I already ate them all... see you in a minute\\r\\nOllie: ok'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "dataset_samsum['test'][4]['dialogue']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1n96qIREMQl"
      },
      "source": [
        "This code uses the Hugging Face Transformers library to generate a summary of the dialogue using the \"google/pegasus-cnn_dailymail\" model and prints the summary.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHxXy-i-aBKX",
        "outputId": "1bc1ebcd-dd8e-4d47-d163-23740450f6e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-cnn_dailymail and are newly initialized: ['model.encoder.embed_positions.weight', 'model.decoder.embed_positions.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'summary_text': \"Ollie calls Jane to ask if she has any more whisky .<n>Jane is worried that Ollie has a spy in his mobile phone .<n>The pair discuss Jane's upcoming trip to Morocco .\"}]\n"
          ]
        }
      ],
      "source": [
        "pipe = pipeline('summarization', model = model_ckpt )\n",
        "pipe_out = pipe(dataset_samsum['test'][4]['dialogue'] )\n",
        "print(pipe_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bRLT5yEUrA"
      },
      "source": [
        "This code prints the generated summary by accessing the \"summary_text\" field from the `pipe_out` result and replaces \"<n>\" with a newline character to format it properly.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbGSyAP5aBHn",
        "outputId": "529be86c-016f-4eda-c5a9-4d2985554f02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ollie calls Jane to ask if she has any more whisky.\n",
            "Jane is worried that Ollie has a spy in his mobile phone.\n",
            "The pair discuss Jane's upcoming trip to Morocco .\n"
          ]
        }
      ],
      "source": [
        "print(pipe_out[0]['summary_text'].replace(\" .<n>\", \".\\n\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YqXIjwHVEfeA"
      },
      "source": [
        "This code loads the ROUGE metric, calculates ROUGE scores on the \"samsum\" dataset's test split using a Pegasus model for summarization and a specified tokenizer. The calculated scores are stored in the 'score' variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQYsFtl3aBEw",
        "outputId": "57ae7787-8420-4f32-827b-84fe36bbbfe7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-a2af470ab8ec>:1: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge_metric = load_metric('rouge')\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [19:15<00:00, 11.21s/it]\n"
          ]
        }
      ],
      "source": [
        "rouge_metric = load_metric('rouge')\n",
        "score = evaluate_model_metric(dataset_samsum['test'], rouge_metric, model_pegasus, tokenizer, text_column = 'dialogue', summary_column='summary', batch_size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FNX32zhCEnzf"
      },
      "source": [
        "This code computes ROUGE scores for \"rouge1,\" \"rouge2,\" \"rougeL,\" and \"rougeLsum\" on a summarization model's output and creates a Pandas DataFrame with these scores, labeled under the 'pegasus' index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "x2yhgYIkYozf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "48bbff0c-4850-4d9f-a60b-1eba1756c7c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           rouge1    rouge2    rougeL  rougeLsum\n",
              "pegasus  0.015529  0.000294  0.015501   0.015531"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dd94ede9-ecaf-4411-8ede-3593dd439b1d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pegasus</th>\n",
              "      <td>0.015529</td>\n",
              "      <td>0.000294</td>\n",
              "      <td>0.015501</td>\n",
              "      <td>0.015531</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd94ede9-ecaf-4411-8ede-3593dd439b1d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-dd94ede9-ecaf-4411-8ede-3593dd439b1d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-dd94ede9-ecaf-4411-8ede-3593dd439b1d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
        "pd.DataFrame(rouge_dict, index = ['pegasus'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QylIfPghxhk6"
      },
      "source": [
        "# Histogram\n",
        "\n",
        "\n",
        "This code calculates the token lengths for both dialogue and summary texts in the training dataset and creates two histograms to visualize the token length distributions. The left histogram represents dialogue token lengths, and the right histogram represents summary token lengths. The plots provide insights into the distribution of token lengths in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "sbVwPRzSg-eJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "0b42e1f5-e59e-49d1-c594-d435101a4579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 1024). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "dialog_token_lengths = len([tokenizer.encode(s) for s in dataset_samsum['train']['dialogue']])\n",
        "sum_token_lengths = len([tokenizer.encode(s) for s in dataset_samsum['train']['summary']])\n",
        "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
        "axes[0].hist(dialog_token_lengths, bins=20, color='C0', edgecolor='C0')\n",
        "axes[0].set_title(\"Dialog Token Length\")\n",
        "axes[0].set_xlabel(\"Length\")\n",
        "axes[0].set_ylabel(\"Count\")\n",
        "axes[1].hist(sum_token_lengths, bins=20, color='C0', edgecolor='C0')\n",
        "axes[1].set_title(\"Summary Token Length\")\n",
        "axes[1].set_xlabel(\"Length\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jh-ISZrTE1tZ"
      },
      "source": [
        "This code defines a function, `preprocess_data_batch`, to convert example batches into tokenized features for dialogue and summary texts. It utilizes the Hugging Face Transformers tokenizer to preprocess the data. The resulting processed dataset is stored in `dataset_samsum_pt`, which is batched for further use in training or evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "eKSxsVCGg-bg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "9dfe2a66a42148f091ceebf559ff7046",
            "c5ed0994572e4da9940bd6076515e8fe",
            "8ba7edea32134433b2226260b104914c",
            "366f6e67ad3548498e58ad418e5cd00e",
            "b9e8e5526c944225b4ce7c69bc86fe8b",
            "7797ff6bff014eb98a6e701061a1512f",
            "72936f342a61404ca7c1166acd3908e6",
            "27dcac2fa7ed48eca0793022a87dfe20",
            "04ea32f8c2614ce399819d1fb8d3b21d",
            "3ae9ae51eaef4720a0390e496ec267a3",
            "64f08ceb12e6466aa2f5d1e9dda8e6f9"
          ]
        },
        "outputId": "e4f61602-1cd8-493c-e7ba-0c120a9857ae"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/819 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9dfe2a66a42148f091ceebf559ff7046"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:3856: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "def preprocess_data_batch(example_batch):\n",
        "    input_encodings = tokenizer(example_batch['dialogue'], max_length=1024, truncation=True)\n",
        "\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        target_encodings = tokenizer(example_batch['summary'], max_length=128, truncation=True)\n",
        "\n",
        "    return {\n",
        "        'input_ids': input_encodings['input_ids'],\n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'labels': target_encodings['input_ids']\n",
        "    }\n",
        "\n",
        "dataset_samsum_pt = dataset_samsum.map(preprocess_data_batch, batched=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rm0rCORRFB7d"
      },
      "source": [
        "This code initializes a data collator specifically designed for sequence-to-sequence tasks using the Hugging Face Transformers library. It is configured to work with the Pegasus model and tokenizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "9b0_45Neg-Y4"
      },
      "outputs": [],
      "source": [
        "from transformers import DataCollatorForSeq2Seq\n",
        "seq2seq_data_collator = DataCollatorForSeq2Seq(tokenizer, model=model_pegasus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlEsjcWuFKAM"
      },
      "source": [
        "This code mounts Google Drive to the '/content/drive' directory in a Google Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "CEkFXxyhpan7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6629fef5-121e-4a20-d33d-6e5e8f03d185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHolUqixFRSQ"
      },
      "source": [
        "This command changes the current directory to 'MyDrive' in the Google Drive directory mounted in a Google Colab environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Sbe5ahpmpu9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bc05580-f253-44a3-edbf-b5531ab27be8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF6AtbfZFgOs"
      },
      "source": [
        "This code defines training arguments for a transformer model using the Hugging Face Transformers library, specifying parameters such as output directory, training duration, batch sizes, evaluation settings, and logging intervals."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import accelerate\n",
        "import transformers\n",
        "\n",
        "transformers.__version__, accelerate.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snkNy1kvuFEf",
        "outputId": "545c0eba-37ee-453c-a3a3-b045f02b6155"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('4.35.2', '0.24.1')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "cMYgv4lNg-Vw"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments, Trainer\n",
        "trainer_args = TrainingArguments(\n",
        "    output_dir='pegasus-samsum', num_train_epochs=1, warmup_steps=500,\n",
        "    per_device_train_batch_size=1, per_device_eval_batch_size=1,\n",
        "    weight_decay=0.01, logging_steps=10,\n",
        "    evaluation_strategy='steps', eval_steps=500, save_steps=1e6,\n",
        "    gradient_accumulation_steps=16\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TaN8s5KgFnm5"
      },
      "source": [
        "This code sets up a trainer for fine-tuning a Pegasus model on a summarization task, configuring the model, training arguments, tokenizer, data collator, and training and evaluation datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "wCXvnV_4xrTR"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model=model_pegasus, args=trainer_args,\n",
        "                  tokenizer=tokenizer, data_collator=seq2seq_data_collator,\n",
        "                  train_dataset=dataset_samsum_pt[\"train\"],\n",
        "                  eval_dataset=dataset_samsum_pt[\"validation\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOfS5Gk1FuQm"
      },
      "source": [
        "This code initiates the training process for the configured model using the specified trainer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "qZRakE4ixuVx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "ecf961fc-17b5-4de5-9a68-717483bf4315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a PegasusTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='920' max='920' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [920/920 46:56, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.626500</td>\n",
              "      <td>1.484255</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=920, training_loss=1.8238315105438232, metrics={'train_runtime': 2819.5526, 'train_samples_per_second': 5.225, 'train_steps_per_second': 0.326, 'total_flos': 5526698901602304.0, 'train_loss': 1.8238315105438232, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zW-iaesXF5Qg"
      },
      "source": [
        "This code calculates ROUGE scores for a test dataset using a fine-tuned Pegasus model and then creates a Pandas DataFrame with the computed ROUGE scores, labeled under 'pegasus'."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zkmmsl2z3MxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "JDkHo-dWxrPB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        },
        "outputId": "88af64c5-f147-4cbf-f523-83fee16e7370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 410/410 [13:54<00:00,  2.04s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           rouge1    rouge2    rougeL  rougeLsum\n",
              "pegasus  0.018575  0.000325  0.018426   0.018444"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3fdedaf2-baf4-4b41-b129-67ce18f01114\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>pegasus</th>\n",
              "      <td>0.018575</td>\n",
              "      <td>0.000325</td>\n",
              "      <td>0.018426</td>\n",
              "      <td>0.018444</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3fdedaf2-baf4-4b41-b129-67ce18f01114')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3fdedaf2-baf4-4b41-b129-67ce18f01114 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3fdedaf2-baf4-4b41-b129-67ce18f01114');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "score = evaluate_model_metric(\n",
        "    dataset_samsum['test'], rouge_metric, trainer.model, tokenizer, batch_size = 2, text_column = 'dialogue', summary_column= 'summary'\n",
        ")\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure ) for rn in rouge_names )\n",
        "pd.DataFrame(rouge_dict, index = [f'pegasus'] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsM9i2MuGAub"
      },
      "source": [
        "This code saves the fine-tuned Pegasus model to the directory \"pegasus-samsum-model.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8duofLyGTku3"
      },
      "outputs": [],
      "source": [
        "## Save model\n",
        "model_pegasus.save_pretrained(\"pegasus-samsum-model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gwz7I1fGGVn"
      },
      "source": [
        "This code saves the tokenizer associated with the fine-tuned Pegasus model to the \"tokenizer\" directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "HfHbqWQoUJ1O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe73ffd-a5da-49e6-e1f0-d7a71786d5ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizer/tokenizer_config.json',\n",
              " 'tokenizer/special_tokens_map.json',\n",
              " 'tokenizer/spiece.model',\n",
              " 'tokenizer/added_tokens.json',\n",
              " 'tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "## Save tokenizer\n",
        "tokenizer.save_pretrained(\"tokenizer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jAxQeNWlxzjy"
      },
      "source": [
        "# Test\n",
        "\n",
        "This code loads the \"samsum\" dataset using the Hugging Face datasets library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "FkkMcgGKUy7V"
      },
      "outputs": [],
      "source": [
        "dataset_samsum = load_dataset(\"samsum\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2nQLZW1GWnb"
      },
      "source": [
        "This code initializes a tokenizer using a pretrained tokenizer saved in the \"tokenizer\" directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "06o0uV9DVJhQ"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"tokenizer\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Czv5r_7KGdGu"
      },
      "source": [
        "This code extracts a sample dialogue and its corresponding reference summary from the \"samsum\" dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "JT8yWCAB1WAZ"
      },
      "outputs": [],
      "source": [
        "sample_text = dataset_samsum[\"test\"][4][\"dialogue\"]\n",
        "reference = dataset_samsum[\"test\"][4][\"summary\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJqeBPlMGmC0"
      },
      "source": [
        "This code sets up a text summarization pipeline using a fine-tuned Pegasus model (\"pegasus-samsum-model\") and the associated tokenizer. It defines generation parameters for the pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "rSOKE9fC1eUh"
      },
      "outputs": [],
      "source": [
        "gen_kwargs = {\"length_penalty\": 0.8, \"num_beams\":8, \"max_length\": 128}\n",
        "pipe = pipeline(\"summarization\", model=\"pegasus-samsum-model\",tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIx-VFViGsqC"
      },
      "source": [
        "This code prints a dialogue, its reference summary, and the summary generated by the Pegasus model for the given sample text using the specified generation parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RZPa0R4wxrMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c628215-343c-4fe4-bea8-800392ca3da5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dialogue:\n",
            "Ollie: Hi , are you in Warsaw\r\n",
            "Jane: yes, just back! Btw are you free for diner the 19th?\r\n",
            "Ollie: nope!\r\n",
            "Jane: and the  18th?\r\n",
            "Ollie: nope, we have this party and you must be there, remember?\r\n",
            "Jane: oh right! i lost my calendar..  thanks for reminding me\r\n",
            "Ollie: we have lunch this week?\r\n",
            "Jane: with pleasure!\r\n",
            "Ollie: friday?\r\n",
            "Jane: ok\r\n",
            "Jane: what do you mean \" we don't have any more whisky!\" lol..\r\n",
            "Ollie: what!!!\r\n",
            "Jane: you just call me and the all thing i heard was that sentence about whisky... what's wrong with you?\r\n",
            "Ollie: oh oh... very strange! i have to be carefull may be there is some spy in my mobile! lol\r\n",
            "Jane: dont' worry, we'll check on friday.\r\n",
            "Ollie: don't forget to bring some sun with you\r\n",
            "Jane: I can't wait to be in Morocco..\r\n",
            "Ollie: enjoy and see you friday\r\n",
            "Jane: sorry Ollie, i'm very busy, i won't have time for lunch  tomorrow, but may be at 6pm after my courses?this trip to Morocco was so nice, but time consuming!\r\n",
            "Ollie: ok for tea!\r\n",
            "Jane: I'm on my way..\r\n",
            "Ollie: tea is ready, did you bring the pastries?\r\n",
            "Jane: I already ate them all... see you in a minute\r\n",
            "Ollie: ok\n",
            "\n",
            "Reference Summary:\n",
            "Jane is in Warsaw. Ollie and Jane has a party. Jane lost her calendar. They will get a lunch this week on Friday. Ollie accidentally called Jane and talked about whisky. Jane cancels lunch. They'll meet for a tea at 6 pm.\n",
            "\n",
            "Model Summary:\n",
            "Jane is back in Warsaw. She lost her calendar. She's going to meet with Ollie on Friday. She'll bring some sun with her.\n"
          ]
        }
      ],
      "source": [
        "print(\"Dialogue:\")\n",
        "print(sample_text)\n",
        "print(\"\\nReference Summary:\")\n",
        "print(reference)\n",
        "print(\"\\nModel Summary:\")\n",
        "print(pipe(sample_text, **gen_kwargs)[0][\"summary_text\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4hCxW5y7FTPW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9dfe2a66a42148f091ceebf559ff7046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c5ed0994572e4da9940bd6076515e8fe",
              "IPY_MODEL_8ba7edea32134433b2226260b104914c",
              "IPY_MODEL_366f6e67ad3548498e58ad418e5cd00e"
            ],
            "layout": "IPY_MODEL_b9e8e5526c944225b4ce7c69bc86fe8b"
          }
        },
        "c5ed0994572e4da9940bd6076515e8fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7797ff6bff014eb98a6e701061a1512f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_72936f342a61404ca7c1166acd3908e6",
            "value": "Map: 100%"
          }
        },
        "8ba7edea32134433b2226260b104914c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27dcac2fa7ed48eca0793022a87dfe20",
            "max": 819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04ea32f8c2614ce399819d1fb8d3b21d",
            "value": 819
          }
        },
        "366f6e67ad3548498e58ad418e5cd00e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae9ae51eaef4720a0390e496ec267a3",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_64f08ceb12e6466aa2f5d1e9dda8e6f9",
            "value": " 819/819 [00:00&lt;00:00, 1740.36 examples/s]"
          }
        },
        "b9e8e5526c944225b4ce7c69bc86fe8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7797ff6bff014eb98a6e701061a1512f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72936f342a61404ca7c1166acd3908e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27dcac2fa7ed48eca0793022a87dfe20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04ea32f8c2614ce399819d1fb8d3b21d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ae9ae51eaef4720a0390e496ec267a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64f08ceb12e6466aa2f5d1e9dda8e6f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}